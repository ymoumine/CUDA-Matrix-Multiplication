{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "CJJb8CYIOQS4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiJDWNUFHSdO",
        "outputId": "537990d1-62cf-4f1b-b372-1962f6045566"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Nov 16 14:59:07 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XT4gq7MH0Pu",
        "outputId": "33f5d76b-e308-41f0-fbf1-f5071e189741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connected to cloud.r-project.org (3.163.125.119)] [C\r0% [Waiting for headers] [Waiting for headers] [Connected to cloud.r-project.org (3.163.125.119)] [C\r                                                                                                    \rGet:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,110 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,482 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,425 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,164 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,616 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,701 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,453 kB]\n",
            "Fetched 20.3 MB in 5s (3,977 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNsmKocgH--X",
        "outputId": "1e3dc9cc-88bd-47f5-bf1d-3a80cf3820e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Some packages could not be installed. This may mean that you have\n",
            "requested an impossible situation or if you are using the unstable\n",
            "distribution that some required packages have not yet been created\n",
            "or been moved out of Incoming.\n",
            "The following information may help to resolve the situation:\n",
            "\n",
            "The following packages have unmet dependencies:\n",
            " nvidia-driver-565-open : Depends: libnvidia-gl-565 (= 565.57.01-0ubuntu1) but it is not installable\n",
            "                          Depends: nvidia-dkms-565-open (= 565.57.01-0ubuntu1) but it is not installable\n",
            "                          Depends: nvidia-kernel-common-565 (= 565.57.01-0ubuntu1) but it is not installable\n",
            "                          Depends: nvidia-kernel-source-565-open (= 565.57.01-0ubuntu1) but it is not installable\n",
            "                          Depends: libnvidia-compute-565 (= 565.57.01-0ubuntu1) but it is not installable\n",
            "                          Depends: libnvidia-extra-565 (= 565.57.01-0ubuntu1) but it is not installable\n",
            "                          Depends: nvidia-compute-utils-565 (= 565.57.01-0ubuntu1) but it is not installable\n",
            "                          Depends: libnvidia-decode-565 (= 565.57.01-0ubuntu1) but it is not installable\n",
            "                          Depends: libnvidia-encode-565 (= 565.57.01-0ubuntu1) but it is not installable\n",
            "                          Depends: nvidia-utils-565 (= 565.57.01-0ubuntu1) but it is not installable\n",
            "                          Depends: xserver-xorg-video-nvidia-565 (= 565.57.01-0ubuntu1) but it is not installable\n",
            "                          Depends: libnvidia-cfg1-565 (= 565.57.01-0ubuntu1) but it is not installable\n",
            "                          Depends: libnvidia-fbc1-565 (= 565.57.01-0ubuntu1) but it is not installable\n",
            "                          Recommends: libnvidia-compute-565:i386 (= 565.57.01-0ubuntu1)\n",
            "                          Recommends: libnvidia-decode-565:i386 (= 565.57.01-0ubuntu1)\n",
            "                          Recommends: libnvidia-encode-565:i386 (= 565.57.01-0ubuntu1)\n",
            "                          Recommends: libnvidia-fbc1-565:i386 (= 565.57.01-0ubuntu1)\n",
            "                          Recommends: libnvidia-gl-565:i386 (= 565.57.01-0ubuntu1)\n",
            "E: Unable to correct problems, you have held broken packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Implémentation Baseline"
      ],
      "metadata": {
        "id": "DpGnFzIaCV3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrice_multiplication_global_baseline.cu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeUopccfIGeU",
        "outputId": "4c2ffc8d-171a-471d-f148-0f6fcd513568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrice_multiplication_global_baseline.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrice_multiplication_global_baseline.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "\n",
        "#define N 512  // Taille des matrices carrées (N x N)\n",
        "\n",
        "__global__ void matrixMultiply(const float* A, const float* B, float* C, int n) {\n",
        "    // Obtenir l'indice de la ligne et de la colonne pour le thread actuel\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Calculer l'élément de la matrice résultat C\n",
        "    if (row < n && col < n) {\n",
        "        float sum = 0.0f;\n",
        "        for (int k = 0; k < n; ++k) {\n",
        "            sum += A[row * n + k] * B[k * n + col];\n",
        "        }\n",
        "        C[row * n + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int size = N * N * sizeof(float);\n",
        "    float *h_A, *h_B, *h_C;\n",
        "    float *d_A, *d_B, *d_C;\n",
        "\n",
        "    // Allocation de la mémoire hôte\n",
        "    h_A = (float*)malloc(size);\n",
        "    h_B = (float*)malloc(size);\n",
        "    h_C = (float*)malloc(size);\n",
        "\n",
        "    // Initialisation des matrices A et B avec des valeurs arbitraires\n",
        "    for (int i = 0; i < N * N; i++) {\n",
        "        h_A[i] = 1.0f;  // exemple de valeurs\n",
        "        h_B[i] = 1.0f;\n",
        "    }\n",
        "\n",
        "    // Allocation de la mémoire sur le périphérique (GPU)\n",
        "    cudaMalloc((void**)&d_A, size);\n",
        "    cudaMalloc((void**)&d_B, size);\n",
        "    cudaMalloc((void**)&d_C, size);\n",
        "\n",
        "    // Copie des matrices A et B de l'hôte vers le périphérique\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Configuration de la grille et des blocs\n",
        "    dim3 threadsPerBlock(16, 16);\n",
        "    dim3 blocksPerGrid((N + threadsPerBlock.x - 1) / threadsPerBlock.x,\n",
        "                       (N + threadsPerBlock.y - 1) / threadsPerBlock.y);\n",
        "\n",
        "    // Lancer le noyau CUDA\n",
        "    matrixMultiply<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, N);\n",
        "\n",
        "    // Copier le résultat du périphérique vers l'hôte\n",
        "    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Vérification du résultat (optionnel)\n",
        "    std::cout << \"Exemple de sortie (C[0][0]): \" << h_C[0] << std::endl;\n",
        "\n",
        "    // Libération de la mémoire\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBxsCgWaIM-9",
        "outputId": "c8324fba-7d34-4060-9783-bfe0d4ab9e81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matrice_multiplication_global_baseline.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc matrice_multiplication_global_baseline.cu -o matrice_multiplication_global_baseline"
      ],
      "metadata": {
        "id": "FrcmrePcJTlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./matrice_multiplication_global_baseline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzSAoZtUJyNu",
        "outputId": "684bc414-cb3a-4e36-d742-4a68c6cec8d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exemple de sortie (C[0][0]): 512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./matrice_multiplication_global_baseline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWymYssVdzhG",
        "outputId": "7aabc513-65e2-423a-a4fc-cb6dc9a7a06b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==964== NVPROF is profiling process 964, command: ./matrice_multiplication_global_baseline\n",
            "Exemple de sortie (C[0][0]): 512\n",
            "==964== Profiling application: ./matrice_multiplication_global_baseline\n",
            "==964== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   81.57%  1.1357ms         1  1.1357ms  1.1357ms  1.1357ms  matrixMultiply(float const *, float const *, float*, int)\n",
            "                   12.56%  174.88us         2  87.438us  87.390us  87.486us  [CUDA memcpy HtoD]\n",
            "                    5.87%  81.694us         1  81.694us  81.694us  81.694us  [CUDA memcpy DtoH]\n",
            "      API calls:   95.71%  68.915ms         3  22.972ms  3.3660us  68.840ms  cudaMalloc\n",
            "                    3.48%  2.5036ms         3  834.54us  233.16us  1.9630ms  cudaMemcpy\n",
            "                    0.31%  223.13us         3  74.375us  12.598us  118.56us  cudaFree\n",
            "                    0.28%  201.05us         1  201.05us  201.05us  201.05us  cudaLaunchKernel\n",
            "                    0.19%  135.14us       114  1.1850us     146ns  54.194us  cuDeviceGetAttribute\n",
            "                    0.02%  11.499us         1  11.499us  11.499us  11.499us  cuDeviceGetName\n",
            "                    0.01%  5.1500us         1  5.1500us  5.1500us  5.1500us  cuDeviceGetPCIBusId\n",
            "                    0.01%  4.2410us         1  4.2410us  4.2410us  4.2410us  cuDeviceTotalMem\n",
            "                    0.00%  1.6370us         3     545ns     182ns  1.1900us  cuDeviceGetCount\n",
            "                    0.00%  1.1610us         2     580ns     175ns     986ns  cuDeviceGet\n",
            "                    0.00%     540ns         1     540ns     540ns     540ns  cuModuleGetLoadingMode\n",
            "                    0.00%     253ns         1     253ns     253ns     253ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Optimisation de l'accès à la mémoire globale"
      ],
      "metadata": {
        "id": "kjf4IN3RCfvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrice_multiplication_global_optimized.cu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94e96876-fc0b-4c58-bdc2-7d1ca6109c40",
        "id": "JC2hCT8sF42t"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrice_multiplication_global_optimized.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrice_multiplication_global_optimized.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "\n",
        "#define N 512  // Taille des matrices carrées (N x N)\n",
        "\n",
        "// Noyau CUDA pour la multiplication de matrices\n",
        "__global__ void matrixMultiply(const float* A, const float* B_T, float* C, int n) {\n",
        "    // Obtenir l'indice de la ligne et de la colonne pour le thread actuel\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Calculer l'élément de la matrice résultat C\n",
        "    if (row < n && col < n) {\n",
        "        float sum = 0.0f;\n",
        "        for (int k = 0; k < n; ++k) {\n",
        "            sum += A[row * n + k] * B_T[col * n + k]; // B_T est transposée\n",
        "        }\n",
        "        C[row * n + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Fonction pour transposer une matrice sur le CPU\n",
        "void transposeMatrix(const float* src, float* dest, int n) {\n",
        "    for (int i = 0; i < n; ++i) {\n",
        "        for (int j = 0; j < n; ++j) {\n",
        "            dest[j * n + i] = src[i * n + j];\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int size = N * N * sizeof(float);\n",
        "    float *h_A, *h_B, *h_B_T, *h_C;\n",
        "    float *d_A, *d_B_T, *d_C;\n",
        "\n",
        "    // Allocation de la mémoire hôte\n",
        "    h_A = (float*)malloc(size);\n",
        "    h_B = (float*)malloc(size);\n",
        "    h_B_T = (float*)malloc(size); // Pour stocker la matrice transposée\n",
        "    h_C = (float*)malloc(size);\n",
        "\n",
        "    // Initialisation des matrices A et B avec des valeurs arbitraires\n",
        "    for (int i = 0; i < N * N; i++) {\n",
        "        h_A[i] = 1.0f;  // Exemple de valeurs\n",
        "        h_B[i] = 1.0f;\n",
        "    }\n",
        "\n",
        "    // Transposer la matrice B sur le CPU\n",
        "    transposeMatrix(h_B, h_B_T, N);\n",
        "\n",
        "    // Allocation de la mémoire sur le périphérique (GPU)\n",
        "    cudaMalloc((void**)&d_A, size);\n",
        "    cudaMalloc((void**)&d_B_T, size);\n",
        "    cudaMalloc((void**)&d_C, size);\n",
        "\n",
        "    // Copie des matrices A et B_T (transposée) de l'hôte vers le périphérique\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B_T, h_B_T, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Configuration de la grille et des blocs\n",
        "    dim3 threadsPerBlock(16, 16);\n",
        "    dim3 blocksPerGrid((N + threadsPerBlock.x - 1) / threadsPerBlock.x,\n",
        "                       (N + threadsPerBlock.y - 1) / threadsPerBlock.y);\n",
        "\n",
        "    // Lancer le noyau CUDA\n",
        "    matrixMultiply<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B_T, d_C, N);\n",
        "\n",
        "    // Copier le résultat du périphérique vers l'hôte\n",
        "    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Vérification du résultat (optionnel)\n",
        "    std::cout << \"Exemple de sortie (C[0][0]): \" << h_C[0] << std::endl;\n",
        "\n",
        "    // Libération de la mémoire\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_B_T);\n",
        "    free(h_C);\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B_T);\n",
        "    cudaFree(d_C);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c69d2d72-ead1-4369-8cd1-88ec68a06f44",
        "id": "UYcU5uZLF-QP"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matrice_multiplication_global_optimized.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc matrice_multiplication_global_optimized.cu -o matrice_multiplication_global_optimized"
      ],
      "metadata": {
        "id": "KIwFxMyiGHrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./matrice_multiplication_global_optimized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4246c8b-0855-4633-b07d-dbe229bec873",
        "id": "WLVftxGkGJr5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exemple de sortie (C[0][0]): 512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./matrice_multiplication_global_optimized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "633f452d-b3d2-4ef6-81f1-e7f8aac18f09",
        "id": "yUYDwLmcGLsu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==1185== NVPROF is profiling process 1185, command: ./matrice_multiplication_global_optimized\n",
            "Exemple de sortie (C[0][0]): 512\n",
            "==1185== Profiling application: ./matrice_multiplication_global_optimized\n",
            "==1185== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   95.92%  6.5611ms         1  6.5611ms  6.5611ms  6.5611ms  matrixMultiply(float const *, float const *, float*, int)\n",
            "                    2.56%  175.39us         2  87.694us  87.614us  87.774us  [CUDA memcpy HtoD]\n",
            "                    1.52%  104.00us         1  104.00us  104.00us  104.00us  [CUDA memcpy DtoH]\n",
            "      API calls:   91.55%  92.703ms         3  30.901ms  7.0670us  92.624ms  cudaMalloc\n",
            "                    7.85%  7.9501ms         3  2.6500ms  237.32us  7.4050ms  cudaMemcpy\n",
            "                    0.23%  232.00us         3  77.334us  14.623us  119.76us  cudaFree\n",
            "                    0.20%  202.60us         1  202.60us  202.60us  202.60us  cudaLaunchKernel\n",
            "                    0.14%  142.33us       114  1.2480us     138ns  57.448us  cuDeviceGetAttribute\n",
            "                    0.01%  12.186us         1  12.186us  12.186us  12.186us  cuDeviceGetName\n",
            "                    0.01%  5.5180us         1  5.5180us  5.5180us  5.5180us  cuDeviceGetPCIBusId\n",
            "                    0.00%  4.5050us         1  4.5050us  4.5050us  4.5050us  cuDeviceTotalMem\n",
            "                    0.00%  1.7160us         3     572ns     203ns  1.1550us  cuDeviceGetCount\n",
            "                    0.00%  1.2800us         2     640ns     235ns  1.0450us  cuDeviceGet\n",
            "                    0.00%     491ns         1     491ns     491ns     491ns  cuModuleGetLoadingMode\n",
            "                    0.00%     235ns         1     235ns     235ns     235ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Utilisation de la mémoire partagée"
      ],
      "metadata": {
        "id": "TWGDuV0PCl5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrice_multiplication_shared.cu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07eef928-809d-41f7-b3f5-32883b39346e",
        "id": "7KRRIThO5F4K"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrice_multiplication_shared.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrice_multiplication_shared.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "\n",
        "#define TILE_SIZE 16  // Taille de la tuile (TILE_SIZE x TILE_SIZE)\n",
        "#define N 512         // Taille des matrices carrées (N x N)\n",
        "\n",
        "// Noyau CUDA pour la multiplication matricielle optimisée avec mémoire partagée\n",
        "__global__ void matrixMultiplyShared(const float* A, const float* B, float* C, int n) {\n",
        "    // Déclaration de mémoire partagée pour stocker les tuiles de A et B\n",
        "    __shared__ float tile_A[TILE_SIZE][TILE_SIZE];\n",
        "    __shared__ float tile_B[TILE_SIZE][TILE_SIZE];\n",
        "\n",
        "    // Calculer les indices de ligne et de colonne pour le thread actuel\n",
        "    int row = blockIdx.y * TILE_SIZE + threadIdx.y; // Ligne gérée par ce thread\n",
        "    int col = blockIdx.x * TILE_SIZE + threadIdx.x; // Colonne gérée par ce thread\n",
        "    float sum = 0.0f; // Accumulateur pour le produit-somme\n",
        "\n",
        "    // Boucle sur toutes les tuiles nécessaires\n",
        "    for (int tileIdx = 0; tileIdx < (n + TILE_SIZE - 1) / TILE_SIZE; ++tileIdx) {\n",
        "        // Charger une tuile de A dans la mémoire partagée\n",
        "        if (row < n && (tileIdx * TILE_SIZE + threadIdx.x) < n)\n",
        "            tile_A[threadIdx.y][threadIdx.x] = A[row * n + tileIdx * TILE_SIZE + threadIdx.x];\n",
        "        else\n",
        "            tile_A[threadIdx.y][threadIdx.x] = 0.0f;\n",
        "\n",
        "        // Charger une tuile de B dans la mémoire partagée\n",
        "        if (col < n && (tileIdx * TILE_SIZE + threadIdx.y) < n)\n",
        "            tile_B[threadIdx.y][threadIdx.x] = B[(tileIdx * TILE_SIZE + threadIdx.y) * n + col];\n",
        "        else\n",
        "            tile_B[threadIdx.y][threadIdx.x] = 0.0f;\n",
        "\n",
        "        // Synchroniser les threads pour s'assurer que la tuile est complètement chargée\n",
        "        __syncthreads();\n",
        "\n",
        "        // Calcul produit-somme sur la tuile actuelle\n",
        "        for (int k = 0; k < TILE_SIZE; ++k) {\n",
        "            sum += tile_A[threadIdx.y][k] * tile_B[k][threadIdx.x];\n",
        "        }\n",
        "\n",
        "        // Synchroniser les threads avant de charger la prochaine tuile\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Stocker le résultat final dans la mémoire globale\n",
        "    if (row < n && col < n) {\n",
        "        C[row * n + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int size = N * N * sizeof(float); // Taille totale en octets des matrices\n",
        "    float *h_A, *h_B, *h_C;          // Pointeurs pour la mémoire hôte\n",
        "    float *d_A, *d_B, *d_C;          // Pointeurs pour la mémoire périphérique (GPU)\n",
        "\n",
        "    // Allocation de mémoire sur l'hôte\n",
        "    h_A = (float*)malloc(size);\n",
        "    h_B = (float*)malloc(size);\n",
        "    h_C = (float*)malloc(size);\n",
        "\n",
        "    // Initialisation des matrices A et B\n",
        "    for (int i = 0; i < N * N; i++) {\n",
        "        h_A[i] = 1.0f; // Chaque élément de A est 1.0\n",
        "        h_B[i] = 1.0f; // Chaque élément de B est 1.0\n",
        "    }\n",
        "\n",
        "    // Allocation de mémoire sur le GPU\n",
        "    cudaMalloc((void**)&d_A, size);\n",
        "    cudaMalloc((void**)&d_B, size);\n",
        "    cudaMalloc((void**)&d_C, size);\n",
        "\n",
        "    // Copier les matrices A et B depuis l'hôte vers le GPU\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Configuration des dimensions des threads et des blocs\n",
        "    dim3 threadsPerBlock(TILE_SIZE, TILE_SIZE); // Chaque bloc contient TILE_SIZE x TILE_SIZE threads\n",
        "    dim3 blocksPerGrid((N + TILE_SIZE - 1) / TILE_SIZE,\n",
        "                       (N + TILE_SIZE - 1) / TILE_SIZE); // Nombre de blocs nécessaires\n",
        "\n",
        "    // Lancer le noyau CUDA\n",
        "    matrixMultiplyShared<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, N);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Copier le résultat depuis le GPU vers la mémoire hôte\n",
        "    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Afficher un exemple de résultat pour validation\n",
        "    std::cout << \"C[0][0] (Shared): \" << h_C[0] << std::endl;\n",
        "\n",
        "    // Libération de mémoire sur l'hôte et le GPU\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1o_bkmeeRTe",
        "outputId": "0bcbd9d5-51f9-4eb7-fffb-6a8cf8897336"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matrice_multiplication_shared.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc matrice_multiplication_shared.cu -o matrix_multiplication_shared"
      ],
      "metadata": {
        "id": "48W4CpsFdkPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./matrix_multiplication_shared"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoRLJ7fKdwJ8",
        "outputId": "c44fb2bd-9b6d-4d5d-98bb-18fbae0df5bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C[0][0] (Shared): 512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./matrix_multiplication_shared"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e60b57c-138b-4aad-bd41-3a3a556da47b",
        "id": "KNds6xhF4C9L"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==1428== NVPROF is profiling process 1428, command: ./matrix_multiplication_shared\n",
            "C[0][0] (Shared): 512\n",
            "==1428== Profiling application: ./matrix_multiplication_shared\n",
            "==1428== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   73.31%  742.00us         1  742.00us  742.00us  742.00us  matrixMultiplyShared(float const *, float const *, float*, int)\n",
            "                   17.28%  174.88us         2  87.437us  87.262us  87.613us  [CUDA memcpy HtoD]\n",
            "                    9.41%  95.294us         1  95.294us  95.294us  95.294us  [CUDA memcpy DtoH]\n",
            "      API calls:   96.35%  72.931ms         3  24.310ms  3.7850us  72.849ms  cudaMalloc\n",
            "                    1.87%  1.4174ms         3  472.48us  252.28us  844.49us  cudaMemcpy\n",
            "                    0.98%  745.13us         1  745.13us  745.13us  745.13us  cudaDeviceSynchronize\n",
            "                    0.30%  228.87us         3  76.291us  13.476us  119.75us  cudaFree\n",
            "                    0.28%  212.62us         1  212.62us  212.62us  212.62us  cudaLaunchKernel\n",
            "                    0.18%  135.60us       114  1.1890us     146ns  53.092us  cuDeviceGetAttribute\n",
            "                    0.02%  11.448us         1  11.448us  11.448us  11.448us  cuDeviceGetName\n",
            "                    0.01%  5.2480us         1  5.2480us  5.2480us  5.2480us  cuDeviceGetPCIBusId\n",
            "                    0.01%  4.6040us         1  4.6040us  4.6040us  4.6040us  cuDeviceTotalMem\n",
            "                    0.00%  1.3720us         3     457ns     204ns     920ns  cuDeviceGetCount\n",
            "                    0.00%     869ns         2     434ns     189ns     680ns  cuDeviceGet\n",
            "                    0.00%     490ns         1     490ns     490ns     490ns  cuModuleGetLoadingMode\n",
            "                    0.00%     238ns         1     238ns     238ns     238ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Optimiser les schémas d'accès à la mémoire partagée"
      ],
      "metadata": {
        "id": "RTXrb5cNCsCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrice_multiplication_shared_optimized.cu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16sTnZKyApVV",
        "outputId": "32f3858b-b6ef-4acb-dddd-1ff53c30d5b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrice_multiplication_shared_optimized.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrice_multiplication_shared_optimized.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "\n",
        "#define TILE_SIZE 16  // Taille de la tuile (TILE_SIZE x TILE_SIZE)\n",
        "#define PADDING 1         // Padding pour éviter les conflits de banque\n",
        "#define N 512         // Taille des matrices carrées (N x N)\n",
        "\n",
        "// Noyau CUDA pour la multiplication matricielle optimisée avec mémoire partagée et padding\n",
        "__global__ void matrixMultiplySharedOptimized(const float* A, const float* B, float* C, int n) {\n",
        "    // Déclaration de mémoire partagée avec padding\n",
        "    __shared__ float tile_A[TILE_SIZE][TILE_SIZE + PADDING];\n",
        "    __shared__ float tile_B[TILE_SIZE][TILE_SIZE + PADDING];\n",
        "\n",
        "    // Calculer les indices de ligne et de colonne pour le thread actuel\n",
        "    int row = blockIdx.y * TILE_SIZE + threadIdx.y; // Ligne gérée par ce thread\n",
        "    int col = blockIdx.x * TILE_SIZE + threadIdx.x; // Colonne gérée par ce thread\n",
        "    float sum = 0.0f; // Accumulateur pour le produit-somme\n",
        "\n",
        "    // Boucle sur toutes les tuiles nécessaires\n",
        "    for (int tileIdx = 0; tileIdx < (n + TILE_SIZE - 1) / TILE_SIZE; ++tileIdx) {\n",
        "        // Charger une tuile de A dans la mémoire partagée avec padding\n",
        "        if (row < n && (tileIdx * TILE_SIZE + threadIdx.x) < n)\n",
        "            tile_A[threadIdx.y][threadIdx.x] = A[row * n + tileIdx * TILE_SIZE + threadIdx.x];\n",
        "        else\n",
        "            tile_A[threadIdx.y][threadIdx.x] = 0.0f;\n",
        "\n",
        "        // Charger une tuile de B dans la mémoire partagée avec padding\n",
        "        if (col < n && (tileIdx * TILE_SIZE + threadIdx.y) < n)\n",
        "            tile_B[threadIdx.y][threadIdx.x] = B[(tileIdx * TILE_SIZE + threadIdx.y) * n + col];\n",
        "        else\n",
        "            tile_B[threadIdx.y][threadIdx.x] = 0.0f;\n",
        "\n",
        "        // Synchroniser les threads pour s'assurer que la tuile est complètement chargée\n",
        "        __syncthreads();\n",
        "\n",
        "        // Calcul produit-somme sur la tuile actuelle\n",
        "        for (int k = 0; k < TILE_SIZE; ++k) {\n",
        "            sum += tile_A[threadIdx.y][k] * tile_B[k][threadIdx.x];\n",
        "        }\n",
        "\n",
        "        // Synchroniser les threads avant de charger la prochaine tuile\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Stocker le résultat final dans la mémoire globale\n",
        "    if (row < n && col < n) {\n",
        "        C[row * n + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int size = N * N * sizeof(float); // Taille totale en octets des matrices\n",
        "    float *h_A, *h_B, *h_C;          // Pointeurs pour la mémoire hôte\n",
        "    float *d_A, *d_B, *d_C;          // Pointeurs pour la mémoire périphérique (GPU)\n",
        "\n",
        "    // Allocation de mémoire sur l'hôte\n",
        "    h_A = (float*)malloc(size);\n",
        "    h_B = (float*)malloc(size);\n",
        "    h_C = (float*)malloc(size);\n",
        "\n",
        "    // Initialisation des matrices A et B\n",
        "    for (int i = 0; i < N * N; i++) {\n",
        "        h_A[i] = 1.0f; // Chaque élément de A est 1.0\n",
        "        h_B[i] = 1.0f; // Chaque élément de B est 1.0\n",
        "    }\n",
        "\n",
        "    // Allocation de mémoire sur le GPU\n",
        "    cudaMalloc((void**)&d_A, size);\n",
        "    cudaMalloc((void**)&d_B, size);\n",
        "    cudaMalloc((void**)&d_C, size);\n",
        "\n",
        "    // Copier les matrices A et B depuis l'hôte vers le GPU\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Configuration des dimensions des threads et des blocs\n",
        "    dim3 threadsPerBlock(TILE_SIZE, TILE_SIZE); // Chaque bloc contient TILE_SIZE x TILE_SIZE threads\n",
        "    dim3 blocksPerGrid((N + TILE_SIZE - 1) / TILE_SIZE,\n",
        "                       (N + TILE_SIZE - 1) / TILE_SIZE); // Nombre de blocs nécessaires\n",
        "\n",
        "    // Lancer le noyau CUDA optimisé\n",
        "    matrixMultiplySharedOptimized<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, N);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Copier le résultat depuis le GPU vers la mémoire hôte\n",
        "    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Afficher un exemple de résultat pour validation\n",
        "    std::cout << \"C[0][0] (Shared Optimized): \" << h_C[0] << std::endl;\n",
        "\n",
        "    // Libération de mémoire sur l'hôte et le GPU\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d5bab50-25ef-4efc-b311-1a0a2284245b",
        "id": "MOVHGlmjGeu6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matrice_multiplication_shared_optimized.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc matrice_multiplication_shared_optimized.cu -o matrix_multiplication_shared_optimized"
      ],
      "metadata": {
        "id": "5TCWpmjdGky-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./matrix_multiplication_shared_optimized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30a739f9-f05b-4d61-8fc8-68afb5edd82c",
        "id": "6ekk8u-bG1l9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C[0][0] (Shared Optimized): 512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./matrix_multiplication_shared_optimized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f7716bd-99fe-41b1-f1d5-38bb602160d0",
        "id": "ldEl_QjdG4Zm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==1621== NVPROF is profiling process 1621, command: ./matrix_multiplication_shared_optimized\n",
            "C[0][0] (Shared Optimized): 512\n",
            "==1621== Profiling application: ./matrix_multiplication_shared_optimized\n",
            "==1621== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   78.45%  975.69us         1  975.69us  975.69us  975.69us  matrixMultiplySharedOptimized(float const *, float const *, float*, int)\n",
            "                   14.04%  174.65us         2  87.326us  87.294us  87.358us  [CUDA memcpy HtoD]\n",
            "                    7.51%  93.438us         1  93.438us  93.438us  93.438us  [CUDA memcpy DtoH]\n",
            "      API calls:   96.65%  90.084ms         3  30.028ms  6.2770us  90.007ms  cudaMalloc\n",
            "                    1.63%  1.5182ms         3  506.07us  254.94us  948.80us  cudaMemcpy\n",
            "                    1.05%  978.32us         1  978.32us  978.32us  978.32us  cudaDeviceSynchronize\n",
            "                    0.26%  240.11us         3  80.037us  14.679us  124.65us  cudaFree\n",
            "                    0.22%  208.38us         1  208.38us  208.38us  208.38us  cudaLaunchKernel\n",
            "                    0.16%  146.46us       114  1.2840us     146ns  56.985us  cuDeviceGetAttribute\n",
            "                    0.01%  12.311us         1  12.311us  12.311us  12.311us  cuDeviceGetName\n",
            "                    0.01%  6.0520us         1  6.0520us  6.0520us  6.0520us  cuDeviceTotalMem\n",
            "                    0.01%  5.0730us         1  5.0730us  5.0730us  5.0730us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.4820us         3     494ns     184ns     930ns  cuDeviceGetCount\n",
            "                    0.00%  1.0280us         2     514ns     311ns     717ns  cuDeviceGet\n",
            "                    0.00%     349ns         1     349ns     349ns     349ns  cuModuleGetLoadingMode\n",
            "                    0.00%     338ns         1     338ns     338ns     338ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Profilage des performances"
      ],
      "metadata": {
        "id": "YBxt_S5aCzie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrice_multiplication_profiling.cu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpxnncXIF_-l",
        "outputId": "8dd4a1ad-555c-4c98-951b-4b3a2461c2ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrice_multiplication_profiling.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrice_multiplication_profiling.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "\n",
        "// Noyau pour la multiplication matricielle utilisant la mémoire globale\n",
        "__global__ void matMulGlobalMemory(float *A, float *B, float *C, int N) {\n",
        "    // Calcul des indices de ligne et de colonne pour chaque thread\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Vérifier si les indices sont dans les limites de la matrice\n",
        "    if (row < N && col < N) {\n",
        "        float value = 0.0f; // Variable pour accumuler le produit-somme\n",
        "        // Calculer la multiplication matricielle pour cet élément\n",
        "        for (int k = 0; k < N; ++k) {\n",
        "            value += A[row * N + k] * B[k * N + col];\n",
        "        }\n",
        "        C[row * N + col] = value; // Stocker le résultat dans C\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int N = 1024; // Dimension de la matrice (N x N)\n",
        "    // Allouer des matrices A, B, et C sur l'hôte (CPU)\n",
        "    std::vector<float> h_A(N * N, 1.0f); // Matrice A (initialisée à 1)\n",
        "    std::vector<float> h_B(N * N, 1.0f); // Matrice B (initialisée à 1)\n",
        "    std::vector<float> h_C(N * N, 0.0f); // Matrice C (initialisée à 0)\n",
        "\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    // Allocation mémoire sur le GPU pour A, B et C\n",
        "    cudaMalloc(&d_A, N * N * sizeof(float));\n",
        "    cudaMalloc(&d_B, N * N * sizeof(float));\n",
        "    cudaMalloc(&d_C, N * N * sizeof(float));\n",
        "\n",
        "    // Copier les matrices A et B depuis l'hôte vers le GPU\n",
        "    cudaMemcpy(d_A, h_A.data(), N * N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B.data(), N * N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Définir les dimensions des blocs et de la grille\n",
        "    dim3 dimBlock(16, 16, 1);  // Taille du bloc de threads\n",
        "    dim3 dimGrid((N + 15) / 16, (N + 15) / 16, 1); // Nombre de blocs nécessaires\n",
        "\n",
        "    // Lancer le noyau pour effectuer la multiplication matricielle\n",
        "    matMulGlobalMemory<<<dimGrid, dimBlock>>>(d_A, d_B, d_C, N);\n",
        "    cudaDeviceSynchronize(); // Synchroniser l'exécution du noyau\n",
        "\n",
        "    // Copier le résultat de la matrice C du GPU vers l'hôte\n",
        "    cudaMemcpy(h_C.data(), d_C, N * N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Afficher un exemple de résultat pour vérifier\n",
        "    std::cout << \"Exemple de sortie (C[0][0]): \" << h_C[0] << std::endl;\n",
        "\n",
        "    // Libérer la mémoire allouée sur le GPU\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2MUiiq0LrF2",
        "outputId": "45e3fac9-a231-4c96-acfe-e285e562402a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matrice_multiplication_profiling.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc matrice_multiplication_profiling.cu -o matrice_multiplication_profiling"
      ],
      "metadata": {
        "id": "KVT0LXy-MyOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./matrice_multiplication_profiling"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sb8koHRMzKD",
        "outputId": "33bc3b0f-b31a-4293-9a2f-ec0f30f8d33a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exemple de sortie (C[0][0]): 1024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./matrice_multiplication_profiling"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4SyNhwNM1mk",
        "outputId": "ebb1cdc1-2b1b-40c2-f109-522192d594b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==1804== NVPROF is profiling process 1804, command: ./matrice_multiplication_profiling\n",
            "Exemple de sortie (C[0][0]): 1024\n",
            "==1804== Profiling application: ./matrice_multiplication_profiling\n",
            "==1804== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   80.66%  9.1159ms         1  9.1159ms  9.1159ms  9.1159ms  matMulGlobalMemory(float*, float*, float*, int)\n",
            "                   13.68%  1.5458ms         2  772.88us  760.17us  785.58us  [CUDA memcpy HtoD]\n",
            "                    5.66%  639.67us         1  639.67us  639.67us  639.67us  [CUDA memcpy DtoH]\n",
            "      API calls:   86.55%  84.065ms         3  28.022ms  129.78us  83.787ms  cudaMalloc\n",
            "                    9.39%  9.1212ms         1  9.1212ms  9.1212ms  9.1212ms  cudaDeviceSynchronize\n",
            "                    3.07%  2.9787ms         3  992.90us  967.81us  1.0330ms  cudaMemcpy\n",
            "                    0.55%  535.58us         3  178.53us  117.49us  210.81us  cudaFree\n",
            "                    0.27%  262.96us         1  262.96us  262.96us  262.96us  cudaLaunchKernel\n",
            "                    0.14%  138.59us       114  1.2150us     135ns  56.111us  cuDeviceGetAttribute\n",
            "                    0.01%  10.475us         1  10.475us  10.475us  10.475us  cuDeviceGetName\n",
            "                    0.01%  8.7790us         1  8.7790us  8.7790us  8.7790us  cuDeviceGetPCIBusId\n",
            "                    0.00%  4.5190us         1  4.5190us  4.5190us  4.5190us  cuDeviceTotalMem\n",
            "                    0.00%  1.8230us         3     607ns     225ns  1.3580us  cuDeviceGetCount\n",
            "                    0.00%     977ns         2     488ns     184ns     793ns  cuDeviceGet\n",
            "                    0.00%     576ns         1     576ns     576ns     576ns  cuModuleGetLoadingMode\n",
            "                    0.00%     238ns         1     238ns     238ns     238ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Optimisation itérative\n",
        "\n"
      ],
      "metadata": {
        "id": "vvlxeeA_EGLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrice_multiplication_iterative_optimization.cu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDNyeMBNLu4Z",
        "outputId": "862e3f46-ada2-42ee-91ac-64b31a96f639"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrice_multiplication_iterative_optimization.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrice_multiplication_iterative_optimization.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "\n",
        "#define TILE_WIDTH 16 // Taille de la tuile pour la multiplication optimisée\n",
        "\n",
        "// Noyau CUDA pour la multiplication matricielle utilisant la mémoire partagée\n",
        "__global__ void matMulSharedMemory(float *A, float *B, float *C, int N) {\n",
        "    // Déclaration de la mémoire partagée pour les tuiles de A et B\n",
        "    __shared__ float tileA[TILE_WIDTH][TILE_WIDTH];\n",
        "    __shared__ float tileB[TILE_WIDTH][TILE_WIDTH];\n",
        "\n",
        "    // Calcul des indices de ligne et de colonne pour chaque thread\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    float value = 0.0f; // Variable pour accumuler le produit-somme\n",
        "\n",
        "    // Boucle sur les tuiles nécessaires pour la multiplication\n",
        "    for (int t = 0; t < (N + TILE_WIDTH - 1) / TILE_WIDTH; ++t) {\n",
        "        // Charger une tuile de la matrice A dans la mémoire partagée\n",
        "        if (row < N && t * TILE_WIDTH + threadIdx.x < N)\n",
        "            tileA[threadIdx.y][threadIdx.x] = A[row * N + t * TILE_WIDTH + threadIdx.x];\n",
        "        else\n",
        "            tileA[threadIdx.y][threadIdx.x] = 0.0f;\n",
        "\n",
        "        // Charger une tuile de la matrice B dans la mémoire partagée\n",
        "        if (col < N && t * TILE_WIDTH + threadIdx.y < N)\n",
        "            tileB[threadIdx.y][threadIdx.x] = B[(t * TILE_WIDTH + threadIdx.y) * N + col];\n",
        "        else\n",
        "            tileB[threadIdx.y][threadIdx.x] = 0.0f;\n",
        "\n",
        "        // Synchronisation des threads avant le calcul du produit-somme\n",
        "        __syncthreads();\n",
        "\n",
        "        // LE RESTE DU CODE...\n",
        "\n",
        "        // Calculer le produit-somme pour la tuile actuelle\n",
        "        for (int k = 0; k < TILE_WIDTH; ++k) {\n",
        "            value += tileA[threadIdx.y][k] * tileB[k][threadIdx.x];\n",
        "        }\n",
        "\n",
        "        // Synchroniser les threads avant de charger la prochaine tuile\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Stocker le résultat final dans la matrice C\n",
        "    if (row < N && col < N) {\n",
        "        C[row * N + col] = value;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int N = 1024; // Dimension de la matrice (N x N)\n",
        "    // Allouer des matrices A, B, et C sur l'hôte (CPU)\n",
        "    std::vector<float> h_A(N * N, 1.0f); // Matrice A (initialisée à 1)\n",
        "    std::vector<float> h_B(N * N, 1.0f); // Matrice B (initialisée à 1)\n",
        "    std::vector<float> h_C(N * N, 0.0f); // Matrice C (initialisée à 0)\n",
        "\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    // Allocation mémoire sur le GPU pour A, B et C\n",
        "    cudaMalloc(&d_A, N * N * sizeof(float));\n",
        "    cudaMalloc(&d_B, N * N * sizeof(float));\n",
        "    cudaMalloc(&d_C, N * N * sizeof(float));\n",
        "\n",
        "    // Copier les matrices A et B depuis l'hôte vers le GPU\n",
        "    cudaMemcpy(d_A, h_A.data(), N * N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B.data(), N * N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Définir les dimensions des blocs et de la grille\n",
        "    dim3 dimBlock(TILE_WIDTH, TILE_WIDTH, 1);  // Taille du bloc de threads\n",
        "    dim3 dimGrid((N + TILE_WIDTH - 1) / TILE_WIDTH, (N + TILE_WIDTH - 1) / TILE_WIDTH, 1); // Nombre de blocs nécessaires\n",
        "\n",
        "    // Lancer le noyau pour effectuer la multiplication matricielle optimisée\n",
        "    matMulSharedMemory<<<dimGrid, dimBlock>>>(d_A, d_B, d_C, N);\n",
        "    cudaDeviceSynchronize(); // Synchroniser l'exécution du noyau\n",
        "\n",
        "    // Copier le résultat de la matrice C du GPU vers l'hôte\n",
        "    cudaMemcpy(h_C.data(), d_C, N * N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Afficher un exemple de résultat pour vérifier\n",
        "    std::cout << \"Exemple de sortie (C[0][0]): \" << h_C[0] << std::endl;\n",
        "\n",
        "    // Libérer la mémoire allouée sur le GPU\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVTcsdEUL7JX",
        "outputId": "dfa9ce87-a8dd-4f18-a0bd-638c7723be35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matrice_multiplication_iterative_optimization.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc matrice_multiplication_iterative_optimization.cu -o matrice_multiplication_iterative_optimization"
      ],
      "metadata": {
        "id": "oMq6iPj2NAeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./matrice_multiplication_iterative_optimization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS4CmAqcNBmQ",
        "outputId": "4618ea8f-4144-4251-f25b-09a9c06ff63b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exemple de sortie (C[0][0]): 1024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./matrice_multiplication_iterative_optimization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMWknrz7NDlx",
        "outputId": "043c3d7c-3cc0-4a89-c116-428ad5e39c02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==1981== NVPROF is profiling process 1981, command: ./matrice_multiplication_iterative_optimization\n",
            "Exemple de sortie (C[0][0]): 1024\n",
            "==1981== Profiling application: ./matrice_multiplication_iterative_optimization\n",
            "==1981== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   73.09%  5.8026ms         1  5.8026ms  5.8026ms  5.8026ms  matMulSharedMemory(float*, float*, float*, int)\n",
            "                   18.51%  1.4696ms         2  734.82us  732.30us  737.33us  [CUDA memcpy HtoD]\n",
            "                    8.40%  667.09us         1  667.09us  667.09us  667.09us  [CUDA memcpy DtoH]\n",
            "      API calls:   89.99%  87.754ms         3  29.251ms  73.359us  87.602ms  cudaMalloc\n",
            "                    5.95%  5.8050ms         1  5.8050ms  5.8050ms  5.8050ms  cudaDeviceSynchronize\n",
            "                    3.03%  2.9536ms         3  984.54us  916.37us  1.0683ms  cudaMemcpy\n",
            "                    0.56%  542.35us         3  180.78us  126.62us  208.66us  cudaFree\n",
            "                    0.26%  251.15us         1  251.15us  251.15us  251.15us  cudaLaunchKernel\n",
            "                    0.19%  187.51us       114  1.6440us     137ns  96.130us  cuDeviceGetAttribute\n",
            "                    0.01%  11.332us         1  11.332us  11.332us  11.332us  cuDeviceGetName\n",
            "                    0.01%  5.5640us         1  5.5640us  5.5640us  5.5640us  cuDeviceGetPCIBusId\n",
            "                    0.01%  4.9160us         1  4.9160us  4.9160us  4.9160us  cuDeviceTotalMem\n",
            "                    0.00%  1.5690us         3     523ns     194ns  1.0700us  cuDeviceGetCount\n",
            "                    0.00%     955ns         2     477ns     209ns     746ns  cuDeviceGet\n",
            "                    0.00%     544ns         1     544ns     544ns     544ns  cuModuleGetLoadingMode\n",
            "                    0.00%     318ns         1     318ns     318ns     318ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    }
  ]
}